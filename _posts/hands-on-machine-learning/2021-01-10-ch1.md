---
layout : post
title : "[핸즈온 머신러닝 완독 프로젝트] Chaper 1. 머신러닝에 대해서"
categories : [hands on machine learning, 머신러닝]
date : 2021-01-10 20:00
---

## 핸즈온 머신러닝 완독 프로젝트

## 머신러닝 시스템의 종류

### 지도학습과 비지도학습, 그리고 그 종류

- 지도학습 : 훈련 데이터에 **label이 있는 것**
  - 종류는 크게 회귀(regression)과 분류(classification)이 있다.
  - 대표적인 지도학습 알고리즘
    - K-Nearest Neighbors
    - 선형 회귀
    - 로지스틱 회귀
    - 서포트 벡터 머신 (SVM)
    - 결정 트리와 랜덤 포레스트
    - 신경망 (Neural Networks)
- 비지도 학습 : 훈련 데이터에 **label이 없는 것**
  - 군집화가 대표적인 예다.
  - 대표적인 비지도학습 알고리즘
    - 군집 (clustering)
      - k-평균 (k-means)
      - 계층 군집 분석 (Hierarchical Cluster Analysis, HCA)
      - 기댓값 최대화
    - 시각화와 차원축소
      - 주성분분석(PCA)
      - 커널 PCA
      - 지역적 선형 임베딩 (localily-linear embedding, LLE)
      - t-SNE
    - 연관규칙학습
      - 어프라이어리
      - 이클렛
  - 이상치 탐지, 연관 규칙 학습 

### 배치학습과 온라인 학습

머신러닝 시스템을 분류하는데 사용하는 다른 기준은 입력 데이터의 스트림으로부터 점진적으로 학습할 수 있는지 여부입니다.

#### 배치학습 (batch learning)

- 시스템이 점진적으로 학습할 수 없는 학습. 
- 시스템을 학습시키고 제품 시스템에 적용하면 더이상 학습 없이 실행된다. (=오프라인 학습이라고 함)
- 시간과 자원을 많이 소모.
- 전체 데이터 셋을 사용해 훈련한다면 많은 컴퓨팅 자원이 필요함. 
- 새로운 데이터에 대해 학습하려면 시스템을 처음부터 다시 학습시켜야 함. 


#### 온라인 학습 (online learning)

- 데이터를 순차적으로 한 개씩 또는 **미니 배치**라 부르는 작은 묶음 단위로 주입하여 시스템을 훈련하는 학습 방법. 
- 매 학습단계가 빠르고 비용이 적게 듦. 
- 연속적으로 데이터를 받고 학습이 끝난 데이터는 신경쓰지 않기 때문에 한정된 자원 환경애서 학습할 때 좋다.
- 학습률 : 데이터를 얼마나 빠르게 적응할 것인지. 
  - 학습률을 높게 하면 시스템이 데이터에 바르게 적응하지만 예전 데이터를 금방 까먹는다. 
  - 반대로 학습률을 낮게 하면 시스템의 관성이 느려져 느리게 학습된다.

### 사례 기반 학습과 모델 기반 학습

머신러닝 시스템을 어떻게 **일반화**되는가에 따라 분류하는 방법.

#### 사례 기반 학습

- 시스템이 사례를 기억함으로써 학습하는 방법.
- **유사도**(similarity) 측정을 사용해 새로운 데이터에 일반화한다.

#### 모델 기반 학습

- 샘플들의 모델을 만들어 예측에 사용하는 것. 
- 선형회귀, 로지스틱 회귀 등의 **모델 선택**을 통해 학습하는 방식.
- 효용함수와 비용함수
  - **효용 함수**(utilty function) : 모델이 얼마나 좋은지
  - **비용 함수**(cost function) : 모델이 얼마나 나쁜지


## 머신러닝의 주요 도전 과제

1. 충분하지 않은 양의 훈련 데이터
2. 대표성 없는 훈련 데이터
3. 낮은 품질의 데이터
4. 관련 없는 특성
  - 훈련 데이터에 관련 없는 특성이 들어있어서 훈련에 영향을 주는 것.
  - **특성 공학**(feature engineering) : 좋은 특성을 찾는 것 
    - 특성 선택 : 유용한 특성 선택
    - 특성 추출 : 특성들을 결합해 더  유용한 특성 만듦
5. 훈련 데이터 과대 적합
  - overfitting : 훈련 데이터에 너무 충실한 나머지 일반적인 특성을 놓치는 것
  - overfittingd을 줄이는 방법
    - 데이터 특성 수를 줄이거나 단순화 시킴.
    - 훈련 데이터를 더 많이 모으기
    - 훈련 데이터의 잡음 줄이기
  - **규제** : 모델을 단순하게 하기위해 모델에 제약을 가하는 것.
  - **하이퍼파라미터** : 학습하는 동안 적용할 규제.
6. 훈련 데이터 과소 적합
  - underfitting : 제대로 학습되지 못한 것.
  - 해결 방법
    - 모델 파라미터가 더 많은 강력한 모델을 선택한다
    - 학습 알고리즘에 더 좋은 특성을 제공한다
    - 모델의 제약을 줄인다. 


## 테스트와 검증

## test

훈련 데이터를 훈련 세트와 테스트 세트 두개로 나누기

- 새로운 샘플에 대한 오류 비율을 **일반화 오차**, 혹은 외부 샘플 오차라고 한다.
- 보통 데이터의 80%를 훈련에 사용하고 20%는 테스트용으로 떼어 놓는다. 

## validation

- holdout validation
  - 훈련 세트를 사용해 다양한 하이퍼 파라미터로 여러 모델을 훈련시키고 검증 세트에서 최상의 성능을 내는 모델과 하이퍼 파라미터를 선택한다. 
- 교차 검증 (cross validation)
  - 훈련 세트를 여러 서브셋으로 나누고 각 모델을 이 서브셋의 조합으로 훈련시키고 나머지 부분으로 검증한다.


!!!